{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install scikit-learn keras-tuner git+https://github.com/paulgavrikov/visualkeras.git\n",
    "!python --version"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras_tuner\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import layers\n",
    "from keras.utils import timeseries_dataset_from_array, to_categorical\n",
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "import logging\n",
    "from enum import Enum\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "#from utils import load_gesture_samples, GestureNames, split_data_between_participants, normalize_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "\n",
    "print('1: ', tf.config.list_logical_devices())\n",
    "print('2: ', tf.test.is_built_with_cuda())\n",
    "print('3: ', tf.test.gpu_device_name())\n",
    "print('4: ', tf.config.get_visible_devices())\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup logger\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    force = True)\n",
    "\n",
    "log = logging.getLogger(\"CSE3000\")\n",
    "log.setLevel(logging.INFO)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Utility functions cell\n",
    "RANDOM_SEED = 1000\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "class Hand(Enum):\n",
    "    right = \"right_hand\"\n",
    "    left = \"left_hand\"\n",
    "\n",
    "\n",
    "class GestureException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class Gestures(Enum):\n",
    "    SWIPE_LEFT = 0, 'swipe_left'\n",
    "    SWIPE_RIGHT = 1, 'swipe_right'\n",
    "    SWIPE_UP = 2, 'swipe_up'\n",
    "    SWIPE_DOWN = 3, 'swipe_down'\n",
    "    ROT_CW = 4, 'clockwise'\n",
    "    ROT_CCW = 5, 'counter_clockwise'\n",
    "    TAP = 6, 'tap'\n",
    "    DOUBLE_TAP = 7, 'double_tap'\n",
    "    ZOOM_IN = 8, 'zoom_in'\n",
    "    ZOOM_OUT = 9, 'zoom_out'\n",
    "\n",
    "    def __new__(cls, value, name):\n",
    "        member = object.__new__(cls)\n",
    "        member._value_ = value\n",
    "        member.fullname = name\n",
    "        return member\n",
    "\n",
    "    def __int__(self):\n",
    "        return self.value\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fullname\n",
    "\n",
    "    @staticmethod\n",
    "    def from_name(name: str):\n",
    "        try:\n",
    "            return next(g for g in Gestures if g.fullname == name)\n",
    "        except StopIteration:\n",
    "            raise GestureException(\"No gesture with name '%s' found...\" % name)\n",
    "\n",
    "\n",
    "class LoadGestureException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_gesture_samples(gesture: Gestures, hand: Hand = Hand.right, skip_old_data: bool = True):\n",
    "    result = []\n",
    "    base_path = f\"gestures_data/gestures/{gesture.fullname}/{hand.value}\"\n",
    "    log.debug(\"Loading gestures from base path: %s\" % base_path)\n",
    "    folder_items = os.listdir(base_path)\n",
    "\n",
    "    # Filter on the .pickle extension\n",
    "    filtered_ext = list(filter(lambda x: re.search(r'\\.pickle$', x) is not None, folder_items))\n",
    "\n",
    "    if len(filtered_ext) == 0:\n",
    "        raise LoadGestureException(\"No gestures found in folder: %s\" % base_path)\n",
    "\n",
    "    for item in filtered_ext:\n",
    "        r_match = re.match(r'candidate_(\\w+).pickle$', item)\n",
    "        if r_match is None:\n",
    "            raise LoadGestureException(\"Incorrectly formatted data file name: %s\" % item)\n",
    "\n",
    "        candidate_id = r_match.group(1)\n",
    "        with open(os.path.join(base_path, item), 'rb') as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    data_contents = pickle.load(f)\n",
    "\n",
    "                    if isinstance(data_contents, dict):\n",
    "                        if 'target_gesture' in data_contents:\n",
    "                            # Data v3\n",
    "                            # print(data_contents)\n",
    "                            data_contents['gesture'] = Gestures.from_name(data_contents['target_gesture'])\n",
    "                            # data_contents['all_data'] = data_contents['data']\n",
    "                            # print(type(data_contents['data']))\n",
    "                            # data_contents['data'] = list(map(lambda x: x['data'], data_contents['data']))\n",
    "                            result.append(data_contents)\n",
    "                        else:\n",
    "                            # Data v2\n",
    "                            data_contents['gesture'] = Gestures.from_name(data_contents['gesture'])\n",
    "                            if not skip_old_data:\n",
    "                                result.append(data_contents)\n",
    "                    else:\n",
    "                        # Data loader v1\n",
    "                        data = {\n",
    "                            'data': data_contents,\n",
    "                            'gesture': gesture,\n",
    "                            'candidate': candidate_id\n",
    "                        }\n",
    "                        if not skip_old_data:\n",
    "                            result.append(data)\n",
    "                except EOFError:\n",
    "                    break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def split_data_between_participants(data, ratio = 0.7):\n",
    "    lb_candidate = lambda x: x['candidate']\n",
    "\n",
    "    # For itertools.groupby to work we need to sort the data first\n",
    "    data.sort(key=lambda x: x['candidate'])\n",
    "\n",
    "    participants = set(map(lb_candidate, data))\n",
    "    amount_measurements = len(data)\n",
    "    amount_participants = len(participants)\n",
    "\n",
    "    log.debug(\"Participants: %s\" % participants)\n",
    "    log.info(\"Got dataset for %d participants with %d measurements total\" % (amount_participants, amount_measurements))\n",
    "\n",
    "    amount_train = int(amount_measurements * 0.7)\n",
    "    amount_test = amount_measurements - amount_train\n",
    "    log.info(\"Estimating %d measurements for training and %d measurements for test (ratio: %0.1f)\" % (amount_train, amount_test, ratio))\n",
    "\n",
    "    train_data = []\n",
    "    train_data_outcomes = []\n",
    "\n",
    "    test_data = []\n",
    "    test_data_outcomes = []\n",
    "\n",
    "    train_candidates = set()\n",
    "    test_candidates = set()\n",
    "\n",
    "    # Group the data per participant as that is the recommended method for training models\n",
    "    for participant, d in itertools.groupby(data, lb_candidate):\n",
    "        d_list = list(d)\n",
    "\n",
    "        for data_point in d_list:\n",
    "            if len(train_data) < amount_train:\n",
    "                train_candidates.add(participant)\n",
    "                train_data.append(data_point['data'])\n",
    "                train_data_outcomes.append(data_point['gesture'])\n",
    "            else:\n",
    "                test_candidates.add(participant)\n",
    "                test_data.append(data_point['data'])\n",
    "                test_data_outcomes.append(data_point['gesture'])\n",
    "                # test_data.extend([p['data'] for p in d_list])\n",
    "                # test_data_outcomes.extend([p['gesture'].value for p in d_list])\n",
    "\n",
    "    log.info(\"Train candidates: %s\\tTest candidates: %s\" % (train_candidates, test_candidates))\n",
    "\n",
    "    return (np.array(train_data), np.array(train_data_outcomes)), (np.array(test_data), np.array(test_data_outcomes))\n",
    "\n",
    "def normalize_dataset(data):\n",
    "    \"\"\"Watch out this function might not normalize the data as expected, further research required\"\"\"\n",
    "    normalized = []\n",
    "    for graph in data:\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        reshaped = scaler.fit_transform(graph.reshape(-1, graph.shape[-1])).reshape(graph.shape)\n",
    "        normalized.append(reshaped)\n",
    "    return np.array(normalized)\n",
    "\n",
    "def normalize_test(data):\n",
    "    normalized = []\n",
    "    for measurement in data:\n",
    "        mean = measurement.mean()\n",
    "        std = measurement.std()\n",
    "        normalized_measurement = (measurement - mean) / std\n",
    "\n",
    "        normalized.append(normalized_measurement)\n",
    "    return normalized\n",
    "\n",
    "def plot_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    mae = history.history['mae']\n",
    "    val_mae = history.history['val_mae']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(25, 5))\n",
    "\n",
    "    axs[0].plot(epochs, loss, 'g.', label='Training Loss')\n",
    "    axs[0].plot(epochs, val_loss, 'c.', label='Validation Loss')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(epochs, mae, 'g.', label='Training MAE')\n",
    "    axs[1].plot(epochs, val_mae, 'c.', label='Validation MAE')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('MAE')\n",
    "    axs[1].legend()\n",
    "\n",
    "    axs[2].plot(epochs, acc, 'g.', label='Training Accuracy')\n",
    "    axs[2].plot(epochs, val_acc, 'c.', label='Validation Accuracy')\n",
    "    axs[2].set_xlabel('Epochs')\n",
    "    axs[2].set_ylabel('Accuracy')\n",
    "    axs[2].legend()\n",
    "\n",
    "    fig.savefig('output_figures/history_plot.svg')\n",
    "    fig.show()\n",
    "\n",
    "def compile_model(model: keras.Model):\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mae'])\n",
    "\n",
    "def kfold_cross_validation(model: keras.Model, features: np.ndarray, labels: np.ndarray, num_folds: int = 5):\n",
    "    kfold = KFold(num_folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    fold_num = 1\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    confusion_per_fold = []\n",
    "\n",
    "    for train, test in kfold.split(features, labels):\n",
    "        fold_model = keras.models.clone_model(model)\n",
    "        log.info(\"Fold No. %d\" % fold_num)\n",
    "        compile_model(fold_model)\n",
    "        history = fold_model.fit(features[train], labels[train], batch_size=32, epochs=200, verbose=2)\n",
    "        scores = fold_model.evaluate(features[test], labels[test], verbose=2)\n",
    "        predictions = np.argmax(fold_model.predict(features[test]), axis=1)\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        # confusion_per_fold.append(confusion_matrix(labels[test], predictions))\n",
    "\n",
    "        fold_num += 1\n",
    "\n",
    "\n",
    "\n",
    "    return acc_per_fold, loss_per_fold, confusion_per_fold\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined = []\n",
    "\n",
    "# skip_gestures = [Gestures.ZOOM_IN, Gestures.ZOOM_OUT, Gestures.DOUBLE_TAP, Gestures.ROT_CW, Gestures.ROT_CCW]\n",
    "skip_gestures = []\n",
    "# only_gestures = [Gestures.SWIPE_UP, Gestures.SWIPE_DOWN, Gestures.SWIPE_RIGHT, Gestures.SWIPE_LEFT, Gestures.TAP]\n",
    "filtered_gestures = filter(lambda x: x not in skip_gestures, Gestures)\n",
    "filtered_gestures_list = list(filtered_gestures)\n",
    "\n",
    "right_samples_count = 0\n",
    "left_samples_count = 0\n",
    "for g in filtered_gestures_list:\n",
    "    right_samples = load_gesture_samples(g, hand=Hand.right)\n",
    "    left_samples = load_gesture_samples(g, hand=Hand.left)\n",
    "    right_samples_count += len(right_samples)\n",
    "    left_samples_count += len(left_samples)\n",
    "    combined.extend(right_samples)\n",
    "    combined.extend(left_samples)\n",
    "\n",
    "log.info(\"Got %d Right hand measurements and %d Left hand measurements\" % (right_samples_count, left_samples_count))\n",
    "\n",
    "# Deterministic shuffle\n",
    "random.Random(4).shuffle(combined)\n",
    "(x_train, y_train), (x_test, y_test) = split_data_between_participants(combined)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "x_train_normalized = normalize_dataset(x_train)\n",
    "x_test_normalized = normalize_dataset(x_test)\n",
    "\n",
    "y_train = to_categorical(y_train, len(Gestures))\n",
    "y_test = to_categorical(y_test, len(Gestures))\n",
    "\n",
    "# Hardcoded for now, so fix\n",
    "# x_train_normalized = x_train_normalized.reshape((-1, 100, 3, 1))\n",
    "# x_test_normalized = x_test_normalized.reshape((-1, 100, 3, 1))\n",
    "\n",
    "# For CNN\n",
    "input_shape = (25, 4, 3)\n",
    "x_train_reshaped = x_train_normalized.reshape((-1, 25, 4, 3))\n",
    "x_test_reshaped = x_test_normalized.reshape((-1, 25, 4, 3))\n",
    "\n",
    "print(x_train_normalized.shape)\n",
    "print(x_test_normalized.shape)\n",
    "\n",
    "# Combine for K-Fold\n",
    "combined_x = np.concatenate([x_train_normalized, x_test_normalized])\n",
    "combined_y = np.concatenate([y_train, y_test])\n",
    "\n",
    "print(combined_x.shape)\n",
    "print(combined_y.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation for CNN\n",
    "one_sample = x_train_normalized[200]\n",
    "plt.plot(one_sample)\n",
    "plt.savefig('output_figures/sample_graph.svg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reshaped_sample = one_sample.reshape((100, 3))\n",
    "reshaped_sample = np.rot90(one_sample, k=1)\n",
    "print(one_sample.shape)\n",
    "print(reshaped_sample.shape)\n",
    "# plt.plot(one_sample[:,0])\n",
    "plt.imshow(1 - reshaped_sample, cmap='Greys', interpolation='nearest', aspect='auto')\n",
    "plt.yticks([])\n",
    "plt.savefig('output_figures/sample_heatmap.svg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x_train_normalized[0][:,:,:1].shape)\n",
    "one_sample = x_train_normalized[200]\n",
    "image_data = np.concatenate([one_sample[:,:,0], one_sample[:,:,1], one_sample[:,:,2]], axis=1)\n",
    "plt.imshow(1-image_data, cmap='Greys', aspect=1)\n",
    "plt.savefig('output_figures/convolutional_sample.svg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show all training data\n",
    "train_amount = len(x_train)\n",
    "fig, axs = plt.subplots(1, train_amount, figsize=(40, 4))\n",
    "for i in range(train_amount):\n",
    "    axs[i].plot(x_train[i])\n",
    "    axs[i].annotate(Gestures(y_train[i]).fullname, (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show all test data\n",
    "test_amount = len(x_test)\n",
    "fig, axs = plt.subplots(1, test_amount, figsize=(20, 4))\n",
    "for i in range(test_amount):\n",
    "    axs[i].plot(x_test[i])\n",
    "    axs[i].annotate(f'Gesture: {Gestures(y_test[i]).fullname}', (0,0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show normalized test data\n",
    "test_amount = len(x_test_normalized)\n",
    "fig, axs = plt.subplots(1, test_amount, figsize=(20, 4))\n",
    "for i in range(test_amount):\n",
    "    axs[i].plot(x_test_normalized[i])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Implement data windowing\n",
    "# SLICES = 5\n",
    "#\n",
    "# single_source = np.array(train[0], dtype=np.uint16)\n",
    "# single_targets = np.full((single_source.shape[0], 1, 1), train_outcome[0])\n",
    "# print(single_source.shape)\n",
    "#\n",
    "# train_ds = timeseries_dataset_from_array(data=single_source, targets=single_targets, sequence_length=SLICES, sequence_stride=SLICES)\n",
    "#\n",
    "# for example_inputs, example_labels in train_ds.take(1):\n",
    "#     print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "#     print(f'Targets shape (batch, time, features): {example_labels.shape}')\n",
    "#\n",
    "#\n",
    "# single_validation_source = np.array(test[0], dtype=np.uint16)\n",
    "# single_validation_targets = np.full((single_validation_source.shape[0], 1, 1), test_outcome[0])\n",
    "#\n",
    "# validation_ds = keras.utils.timeseries_dataset_from_array(data=single_validation_source, targets=single_validation_targets, sequence_length=SLICES, sequence_stride=SLICES)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_ds = timeseries_dataset_from_array(data=x_train, targets=y_train, sequence_length=SLICES, sequence_stride=SLICES)\n",
    "# validation_ds = timeseries_dataset_from_array(data=x_test, targets=y_test, sequence_length=SLICES, sequence_stride=SLICES)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(dir(train_ds))\n",
    "# print(train_ds.element_spec)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "device = \"/device:GPU:0\" if USE_GPU else \"/device:CPU:0\"\n",
    "\n",
    "def build_cnn_model(shape):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # model_lstm.add(layers.LSTM(units=128, input_shape=[1, 3]))\n",
    "    model.add(layers.Input(shape=shape, name=\"sensor_image\"))\n",
    "    model.add(layers.ZeroPadding2D(padding=(0, 2)))\n",
    "    model.add(layers.Conv2D(8, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(16, kernel_size=(2, 2), strides=(1, 1), activation=\"relu\"))\n",
    "    model.add(layers.Conv2D(16, kernel_size=(2, 2), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 1)))\n",
    "    model.add(layers.Conv2D(32, kernel_size=(5, 1), activation=\"relu\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(len(Gestures), activation=\"softmax\", name=\"predictions\"))\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cnn = build_cnn_model(input_shape)\n",
    "model_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mae'])\n",
    "model_cnn.summary()\n",
    "start = time.perf_counter()\n",
    "simple_history = model_cnn.fit(x_train_reshaped, y_train, epochs=200, batch_size=2, validation_data=(x_test_reshaped, y_test))\n",
    "\n",
    "end = time.perf_counter()\n",
    "print(\"Training took: %0.1f seconds\" % (end - start))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training times:\n",
    "| GPU   | CPU   |\n",
    "|-------|-------|\n",
    "| 18.5s | 12.3s |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(simple_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = model_cnn.evaluate(x_test_normalized, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model_cnn.predict(x_test_reshaped)\n",
    "ConfusionMatrixDisplay.from_predictions(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), normalize='true', cmap='Blues', display_labels=Gestures, xticks_rotation='vertical')\n",
    "\n",
    "plt.title(\"Confusion Matrix CNN\")\n",
    "plt.savefig('output_figures/confusion_matrix_cnn.svg', bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K-Fold validation\n",
    "model_cnn = build_cnn_model(input_shape)\n",
    "(acc_per_fold, loss_per_fold, confusion_per_fold) = kfold_cross_validation(model_cnn, combined_x, combined_y, num_folds=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(acc_per_fold)\n",
    "print(loss_per_fold)\n",
    "print(\"Acc: %.3f std: %.3f\" % (np.average(acc_per_fold), np.std(acc_per_fold)))\n",
    "print(np.average(loss_per_fold))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x_test_normalized.shape)\n",
    "\n",
    "for i in range(x_test_normalized.shape[0]):\n",
    "    test_sample = np.expand_dims(x_test_normalized[i], -4)\n",
    "    test_prediction = model_cnn.predict(test_sample)\n",
    "    print(\"Prediction: %s, actual: %s\" % (Gestures(np.argmax(test_prediction)), Gestures(np.argmax(y_test[i]))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split data visualisation\n",
    "print(x_train_normalized.shape)\n",
    "SEQUENCE_LENGTH = 4\n",
    "\n",
    "for measurement_x, measurement_y in zip(x_train_normalized, y_train):\n",
    "\n",
    "    # Lock the measurement for now:\n",
    "    measurement_x = x_train_normalized[200]\n",
    "    measurement_y = y_train[200]\n",
    "    print(measurement_x.shape)\n",
    "    print(measurement_y.shape)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "    axs[0].plot(measurement_x)\n",
    "    timeseries_train_ds = timeseries_dataset_from_array(measurement_x, measurement_y, sequence_length=SEQUENCE_LENGTH, shuffle=True)\n",
    "\n",
    "    for inputs, targets in timeseries_train_ds:\n",
    "        print(inputs.shape)\n",
    "        print(targets.shape)\n",
    "\n",
    "        print(\"Input length is: %d\" % len(inputs))\n",
    "        for i in range(len(inputs)):\n",
    "            axs[1].plot(np.arange(SEQUENCE_LENGTH * i, SEQUENCE_LENGTH * (i + 1)), inputs[i])\n",
    "            # axs[1].plot(inputs[i])\n",
    "            # plt.plot(np.arange(10 * i, 10 * (i + 1)), np.arange(1, step=0.1))\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "# Split video input visualisation\n",
    "measurement_x = x_train_normalized[200]\n",
    "measurement_y = y_train[200]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axs[0].plot(measurement_x)\n",
    "\n",
    "split_x = np.array(np.array_split(measurement_x, BATCH_SIZE))\n",
    "for i in range(len(split_x)):\n",
    "    axs[1].plot(np.arange((SEQUENCE_LENGTH/BATCH_SIZE) * i, (SEQUENCE_LENGTH/BATCH_SIZE) * (i + 1)), split_x[i])\n",
    "\n",
    "print(split_x.shape)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "device = \"/device:GPU:0\" if USE_GPU else \"/device:CPU:0\"\n",
    "\n",
    "def build_lstm_stateless_model(lstm_units, dense_1_units, dropout):\n",
    "    # https://towardsdatascience.com/time-series-classification-for-human-activity-recognition-with-lstms-using-tensorflow-2-and-keras-b816431afdff\n",
    "    model = keras.Sequential(name=\"LSTM_Stateless\")\n",
    "\n",
    "    # Subject to change as we split up the data in fragments:\n",
    "    # Stateless?\n",
    "    model.add(layers.Input(shape=(100, 3), name=\"sensor_image\"))\n",
    "    model.add(layers.LSTM(units=lstm_units, name=\"lstm\"))\n",
    "    # Stateful?\n",
    "    # model_lstm_stateless.add(layers.Input(batch_shape=(100, 3, 1), name=\"sensor_image\"))\n",
    "    # model_lstm_stateless.add(layers.LSTM(units=128, stateful=True, name=\"lstm\"))\n",
    "\n",
    "    # Extra\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.25, name=\"dropout\"))\n",
    "\n",
    "    model.add(layers.Dense(units=dense_1_units, activation='relu', name=\"dense_1\"))\n",
    "\n",
    "    # Output stage\n",
    "    model.add(layers.Dense(len(Gestures), activation=\"softmax\", name=\"predictions\"))\n",
    "    # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def build_tuning_lstm_stateless_model(hp):\n",
    "    lstm_units = hp.Choice('units', [32, 64, 128, 256, 512, 1024])\n",
    "    dense_1_units = hp.Choice('units', [16, 32, 64, 128, 256, 512, 1024])\n",
    "    dropout = hp.Boolean(\"dropout\")\n",
    "    model = build_lstm_stateless_model(lstm_units, dense_1_units, dropout)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mae'])\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    start = time.perf_counter()\n",
    "    tuner = keras_tuner.RandomSearch(build_tuning_lstm_stateless_model, objective='val_loss', max_trials=20)\n",
    "    tuner.search(x_train_normalized, y_train, epochs=300, batch_size=16, shuffle=False, validation_data=(x_test_normalized, y_test))\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(\"Tuning took %0.1f seconds\" % (end - start))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.get_best_models()[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "device = \"/device:GPU:0\" if USE_GPU else \"/device:CPU:0\"\n",
    "\n",
    "with tf.device(device):\n",
    "    start = time.perf_counter()\n",
    "    # Do we need to reset the states inbetween?\n",
    "\n",
    "    model_lstm_stateless = build_lstm_stateless_model(128, 256, True)\n",
    "    model_lstm_stateless.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mae'])\n",
    "\n",
    "    lstm_stateless_history = model_lstm_stateless.fit(x_train_normalized, y_train, epochs=300, batch_size=16, shuffle=False, validation_data=(x_test_normalized, y_test))\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(\"Training took %0.1f seconds\" % (end - start))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(lstm_stateless_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = model_lstm_stateless.evaluate(x_test_normalized, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "font = ImageFont.truetype(\"RobotoSlab-VariableFont_wght.ttf\", 32)\n",
    "visualkeras.layered_view(model_lstm_stateless, font=font, min_xy=160, scale_z=1, spacing=50, legend=True, to_file='output_figures/visual_lstm_stateless.png').show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model_lstm_stateless.predict(x_test_normalized)\n",
    "ConfusionMatrixDisplay.from_predictions(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), normalize='pred', cmap='Blues', display_labels=Gestures, xticks_rotation='vertical')\n",
    "\n",
    "plt.title(\"Confusion Matrix LSTM\")\n",
    "plt.savefig('output_figures/confusion_matrix_lstm.svg', bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"================= Running on training data (Toy Example): =================\")\n",
    "for i in range(x_train_normalized.shape[0]):\n",
    "    test_sample = np.expand_dims(x_train_normalized[i], -4)\n",
    "    test_prediction = model_lstm_stateless.predict(test_sample)\n",
    "    print(\"Prediction: %s, actual: %s\" % (Gestures(np.argmax(test_prediction)), Gestures(np.argmax(y_train[i]))))\n",
    "\n",
    "print(\"\\n\\n================= Running on testing data: =================\")\n",
    "for i in range(x_test_normalized.shape[0]):\n",
    "    test_sample = np.expand_dims(x_test_normalized[i], -4)\n",
    "    test_prediction = model_lstm_stateless.predict(test_sample)\n",
    "    print(\"Prediction: %s, actual: %s\" % (Gestures(np.argmax(test_prediction)), Gestures(np.argmax(y_test[i]))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K-Fold validation\n",
    "model = build_lstm_stateless_model(128, 256, True)\n",
    "(acc_per_fold, loss_per_fold, confusion_per_fold) = kfold_cross_validation(model, combined_x, combined_y, num_folds=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(acc_per_fold)\n",
    "print(\"Acc: %.3f std: %.3f\" % (np.average(acc_per_fold), np.std(acc_per_fold)))\n",
    "print(np.average(loss_per_fold))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_lstm_stateful_model(lstm_units, dense_1_units, dropout):\n",
    "    # https://towardsdatascience.com/time-series-classification-for-human-activity-recognition-with-lstms-using-tensorflow-2-and-keras-b816431afdff\n",
    "    model = keras.Sequential(name=\"LSTM_Stateful\")\n",
    "\n",
    "    # Subject to change as we split up the data in fragments:\n",
    "    model.add(layers.Input(shape=(100, 3), name=\"sensor_image\"))\n",
    "    model.add(\n",
    "        layers.Bidirectional(\n",
    "            layers.LSTM(units=lstm_units, input_shape=(100, 3), name=\"lstm\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Extra\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate=0.25, name=\"dropout\"))\n",
    "\n",
    "    model.add(layers.Dense(units=dense_1_units, activation='relu', name=\"dense_1\"))\n",
    "\n",
    "    # Output stage\n",
    "    model.add(layers.Dense(len(Gestures), activation=\"softmax\", name=\"predictions\"))\n",
    "    model.summary()\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "device = \"/device:GPU:0\" if USE_GPU else \"/device:CPU:0\"\n",
    "print(x_train_normalized.shape)\n",
    "\n",
    "with tf.device(device):\n",
    "    model_lstm_stateful = build_lstm_stateful_model(128, 128, True)\n",
    "    model_lstm_stateful.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mae'])\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    # Do we need to reset the states inbetween?\n",
    "    lstm_stateful_history = model_lstm_stateful.fit(x_train_normalized, y_train, epochs=200, batch_size=8, shuffle=False, validation_data=(x_test_normalized, y_test))\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print(\"Training took: %0.1f seconds\" % (end - start))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(lstm_stateful_history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = model_lstm_stateful.evaluate(x_test_normalized, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KFold\n",
    "# K-Fold validation\n",
    "model = build_lstm_stateful_model(128, 128, False)\n",
    "\n",
    "(acc_per_fold, loss_per_fold, confusion_per_fold) = kfold_cross_validation(model, combined_x, combined_y, num_folds=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(acc_per_fold)\n",
    "print(\"Acc: %.3f std: %.3f\" % (np.average(acc_per_fold), np.std(acc_per_fold)))\n",
    "print(np.average(loss_per_fold))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model_lstm_stateful.predict(x_test_normalized)\n",
    "ConfusionMatrixDisplay.from_predictions(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), normalize='pred', cmap='Blues', display_labels=Gestures, xticks_rotation='vertical')\n",
    "\n",
    "plt.title(\"Confusion Matrix LSTM\")\n",
    "plt.savefig('output_figures/confusion_matrix_lstm.svg', bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model_lstm_stateful, legend=True).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# taps = list(filter(lambda x: Gestures(x[1]) == Gestures.TAP, zip(x_train_normalized, y_train)))\n",
    "# TODO: Remove the tap gesture that is noise\n",
    "taps = load_gesture_samples(Gestures.TAP, Hand.right)\n",
    "zooms = load_gesture_samples(Gestures.ZOOM_OUT, Hand.right)\n",
    "print(len(taps))\n",
    "random_tap = random.choice(taps)\n",
    "random_zoom = random.choice(zooms)\n",
    "# print(random_plot['candidate'])\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axs[0].plot(random_tap['data'])\n",
    "axs[1].plot(random_zoom['data'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "swipe_ups = load_gesture_samples(Gestures.SWIPE_UP, Hand.right)\n",
    "random_select = random.randint(0, len(swipe_ups))\n",
    "print(\"Randomly selected gesture: %d\" % random_select)\n",
    "selected_swipe_up = swipe_ups[14]['data']\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "normalized_selected = scaler.fit_transform(selected_swipe_up)\n",
    "\n",
    "plt.plot(normalized_selected)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Normalized photodiode reading\")\n",
    "plt.legend(['Top', 'BottomRight', 'BottomLeft'])\n",
    "plt.savefig('output_figures/sample_graph.svg')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n\\n================= Running on testing data: =================\")\n",
    "y_pred = model_lstm_stateful.predict(x_test_normalized)\n",
    "for actual, pred in zip(y_test, y_pred):\n",
    "    pred = Gestures(np.argmax(pred))\n",
    "    actual = Gestures(np.argmax(actual))\n",
    "    if pred == Gestures.SWIPE_RIGHT:\n",
    "        print(\"Prediction: %s, actual: %s\" % (pred, actual))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
